{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación II\n",
    "1. Utilizando la API extraed toda la información que podáis de ella. La url para hacer las llamadas es:\n",
    "`API_URL = \"http://universities.hipolabs.com/search?country=NOMBREPAIS\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llamar_API(lista_paises):\n",
    "    \n",
    "    \"\"\"\n",
    "    Acepta una lista de países y devuelve un dataframe de los datos de los países indicados\n",
    "    obtenidos de la API de hipolabs sobre universidades.\n",
    "    \n",
    "    Parametros:\n",
    "    self.lista_paises: una lista de paises\n",
    "    \n",
    "    Returns:\n",
    "    un dataframe con los datos unidos de todos los paises indicados\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pd.DataFrame()\n",
    "    \n",
    "    for p in lista_paises:\n",
    "        url = f\"http://universities.hipolabs.com/search?country={p}\"\n",
    "        response = requests.get(url=url)\n",
    "        status = response.status_code\n",
    "        razon = response.reason\n",
    "        \n",
    "        if status == 200:\n",
    "            print(f'La peticion al API para {p} se ha realizado con éxito.')\n",
    "        else: \n",
    "            print(f'Respuesta {status}: {razon}')\n",
    "        \n",
    "        df_pais = pd.json_normalize(response.json())\n",
    "    \n",
    "        dataframe = pd.concat([dataframe, df_pais], axis=0)\n",
    "            \n",
    "    print(f'Sus datos ya están listos en un dataframe. Aquí tiene los primeros 3 filas:')\n",
    "    \n",
    "    display(dataframe.head(3))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La peticion al API para Argentina se ha realizado con éxito.\n",
      "La peticion al API para Canada se ha realizado con éxito.\n",
      "La peticion al API para United States se ha realizado con éxito.\n",
      "Sus datos ya están listos en un dataframe. Aquí tiene los primeros 3 filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state-province</th>\n",
       "      <th>domains</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>web_pages</th>\n",
       "      <th>alpha_two_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>[atlantida.edu.ar]</td>\n",
       "      <td>Universidad Atlantida Argentina</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>[http://www.atlantida.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>[austral.edu.ar]</td>\n",
       "      <td>Universidad Austral Buenos Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>[http://www.austral.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>[caece.edu.ar]</td>\n",
       "      <td>Universidad CAECE, Buenos Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>[http://www.caece.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    state-province             domains  \\\n",
       "0                     Buenos Aires  [atlantida.edu.ar]   \n",
       "1                     Buenos Aires    [austral.edu.ar]   \n",
       "2  Ciudad Autónoma de Buenos Aires      [caece.edu.ar]   \n",
       "\n",
       "                               name    country  \\\n",
       "0   Universidad Atlantida Argentina  Argentina   \n",
       "1  Universidad Austral Buenos Aires  Argentina   \n",
       "2   Universidad CAECE, Buenos Aires  Argentina   \n",
       "\n",
       "                        web_pages alpha_two_code  \n",
       "0  [http://www.atlantida.edu.ar/]             AR  \n",
       "1    [http://www.austral.edu.ar/]             AR  \n",
       "2      [http://www.caece.edu.ar/]             AR  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = llamar_API(['Argentina', 'Canada', 'United States'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States    2281\n",
       "Canada            154\n",
       "Argentina          87\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Una vez tengáis todos los datos de la API, deberéis realizar una serie de procesos de limpieza, estos incluyen:\n",
    "- Cambiad los nombres de las columnas para homogeneizarlas, tenemos columnas que tienen - y otras _. Unifícalo para que todo vaya con _.\n",
    "- La columna de domains nos da una información similar a la de web_pages. Eliminad la columna domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limpieza_columnas(dataframe):\n",
    "    \n",
    "    \"\"\"\n",
    "    Acepta un dataframe y realiza dos tareas de limpieza sobre ello:\n",
    "    - reemplaza los guiones por guiones bajos en los nombres de las columnas\n",
    "    - elimina la columna de domains\n",
    "    \n",
    "    Parametros:\n",
    "    - un dataframe de datos extraidos del API de universidades de hipolabs        \n",
    "    \n",
    "    Returns:\n",
    "    - none\n",
    "    \"\"\"\n",
    "    \n",
    "    diccionario = {col : col.replace('-', '_') for col in dataframe.columns}\n",
    "\n",
    "    dataframe.rename(columns=diccionario, inplace=True)\n",
    "    \n",
    "    dataframe.drop(columns='domains', axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Su dataframe se ha limpiado. Aquí tiene la primera fila:\")\n",
    "    display(dataframe.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Su dataframe se ha limpiado. Aquí tiene la primera fila:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_province</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>web_pages</th>\n",
       "      <th>alpha_two_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Atlantida Argentina</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>[http://www.atlantida.edu.ar/]</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_province                             name    country  \\\n",
       "0   Buenos Aires  Universidad Atlantida Argentina  Argentina   \n",
       "\n",
       "                        web_pages alpha_two_code  \n",
       "0  [http://www.atlantida.edu.ar/]             AR  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# llamo a la funcion\n",
    "limpieza_columnas(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Si exploramos la columna de web_pages, nos daremos cuenta que hay universidades, como por ejemplo la Universidad de \"Cégep de Saint-Jérôme\" de Canadá que en su columna de web_pages tiene más de un valor dentro de la lista. Esto es poco práctico y puede llegar a no tener sentido. el objetivo de este ejericio es que usando el método explode de pandas separéis cada elemento de la lista en una fila nueva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2522, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_columna(dataframe, columna):\n",
    "    '''\n",
    "    Acepta un dataframe y columna y separa los valores de la columna que estan en listas, creando una fila por elemento\n",
    "    \n",
    "    Parametros:\n",
    "    - un dataframe\n",
    "    - string: nombre de una columna del dataframe\n",
    "    \n",
    "    Returns:\n",
    "    - un dataframe\n",
    "    '''\n",
    "    return dataframe.explode(columna)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = explode_columna(df, 'web_pages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2535, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Una vez hayáis realizado el explode, chequead si tenéis duplicados basándonos unicamente en el nombre de la universidad, en caso de que si, eliminandlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequeo si hay duplicados de la columna de los nombres de las universidades\n",
    "df['name'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_dup(dataframe, columna):\n",
    "    \n",
    "    '''\n",
    "    Acepta un dataframe y una columna y elimina las filas con valores duplicados de la columna indicada\n",
    "    \n",
    "    Parametros:\n",
    "    - dataframe\n",
    "    - string: nombre de una columna del dataframe\n",
    "    '''\n",
    "    \n",
    "    num_dup = dataframe[columna].duplicated().sum()\n",
    "    dataframe.drop_duplicates(subset=columna, inplace=True)\n",
    "    \n",
    "    print(f'Se han eliminado {num_dup} filas del dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han eliminado 28 filas del dataframe.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2507, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminar_dup(df, 'name')\n",
    "\n",
    "# compruebo que el numero de filas ha cambiado\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Si exploramos la columna de state_province veremos que hay universidades cuyo valor para esta columna es None. Cread una función para reemplazar los None por nulos de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buenos Aires', 'Ciudad Autónoma de Buenos Aires', 'Entre Ríos',\n",
       "       'Salta', 'Córdoba', 'Mendoza', 'Santa Fé', None,\n",
       "       'Santiago Del Estero', 'Misiones', 'Catamarca', 'Formosa', 'Jujuy',\n",
       "       'La Rioja', 'La Pampa', 'San Juan', 'San Luis', 'Tucumán',\n",
       "       'Quebec', 'Ontario', 'Nova Scotia', 'British Columbia', 'Alberta',\n",
       "       'Manitoba', 'New Brunswick', 'Saskatchewan',\n",
       "       'Newfoundland and Labrador', 'Prince Edward Island', 'Yukon',\n",
       "       'Pennsylvania', 'NV', 'Iowa', 'VA', 'TX', 'Colorado', 'IN', 'CA',\n",
       "       'South Carolina', 'Washington', 'NY', 'Texas', 'ND', 'MI', 'Ohio',\n",
       "       'Florida', 'California', 'North Carolina', 'Michigan', 'GA',\n",
       "       'New York, NY'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['state_province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_nan(dataframe, columna):\n",
    "    \n",
    "    '''\n",
    "    Acepta un dataframe y una columna y reemplaza cualquier valor de None por np.nan en \n",
    "    la columna indicada.\n",
    "    \n",
    "    Parametros:\n",
    "    - dataframe\n",
    "    - string: nombre de una columna del dataframe\n",
    "    '''    \n",
    "    \n",
    "    num_none = dataframe[columna].isna().sum()\n",
    "    \n",
    "    dataframe[columna].fillna(value=np.nan, inplace=True)\n",
    "    \n",
    "    print(f'Se han reemplazado {num_none} valores None por np.nan en la columna {columna}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han reemplazado 2234 valores None por np.nan en la columna state_province.\n"
     ]
    }
   ],
   "source": [
    "none_nan(df, 'state_province')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buenos Aires', 'Ciudad Autónoma de Buenos Aires', 'Entre Ríos',\n",
       "       'Salta', 'Córdoba', 'Mendoza', 'Santa Fé', nan,\n",
       "       'Santiago Del Estero', 'Misiones', 'Catamarca', 'Formosa', 'Jujuy',\n",
       "       'La Rioja', 'La Pampa', 'San Juan', 'San Luis', 'Tucumán',\n",
       "       'Quebec', 'Ontario', 'Nova Scotia', 'British Columbia', 'Alberta',\n",
       "       'Manitoba', 'New Brunswick', 'Saskatchewan',\n",
       "       'Newfoundland and Labrador', 'Prince Edward Island', 'Yukon',\n",
       "       'Pennsylvania', 'NV', 'Iowa', 'VA', 'TX', 'Colorado', 'IN', 'CA',\n",
       "       'South Carolina', 'Washington', 'NY', 'Texas', 'ND', 'MI', 'Ohio',\n",
       "       'Florida', 'California', 'North Carolina', 'Michigan', 'GA',\n",
       "       'New York, NY'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compruebo que ya no sale None en los valores unicos de la columna\n",
    "\n",
    "df['state_province'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Después del último cambio, os habréis dado cuenta que tenemos muchos valores nulos dentro de la columna de state_province, por lo que nuestro jefe nos pide que reemplacemos esos nulos por \"Unknow\". No nos piden ningún método especifico, asi que podremos usar el método que queramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_nulos(dataframe, columna, valor_nuevo):\n",
    "    '''\n",
    "    Acepta un dataframe y una columna y reemplaza cualquier valor nulo por el valor nuevo indicado en \n",
    "    la columna indicada.\n",
    "    \n",
    "    Parametros:\n",
    "    - un dataframe\n",
    "    - string: nombre de una columna del dataframe\n",
    "    - string: valor nuevo que queremos en vez de nulos\n",
    "    \n",
    "    Returns:\n",
    "    - none\n",
    "    '''    \n",
    "    num_none = dataframe[columna].isnull().sum()\n",
    "    \n",
    "    dataframe[columna].fillna(value=valor_nuevo, inplace=True)\n",
    "    \n",
    "    print(f'Se han reemplazado {num_none} valores nulos en la columna {columna} por {valor_nuevo}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han reemplazado 2234 valores nulos en la columna state_province por Unknown.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unknown             2234\n",
       "Ontario               46\n",
       "British Columbia      33\n",
       "Pennsylvania          28\n",
       "Quebec                24\n",
       "Name: state_province, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reemplazar_nulos(df, 'state_province', 'Unknown')\n",
    "\n",
    "df['state_province'].value_counts().head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Ahora nuestros jefes nos piden que saquemos las coordenadas de las provincias donde están ubicadas las universidades. Para eso nos piden que usemos la librería de geopy que aprendimos el día del repaso. Para desarrollar este ejercicio deberéis:\n",
    "- Sacar los valores únicos de la columna state_province.\n",
    "- Algunos de los valores que tenemos están con siglas, y deberéis reemplazarlos por lo siguiente:\n",
    "    - NV: reemplazalo por Nevada\n",
    "    - TX: reemplazalo por Texas\n",
    "    - IN: reemplazalo por Indianapolis\n",
    "    - CA: reemplazalo por California\n",
    "    - VA: reemplazalo por Virginia\n",
    "    - NY: reemplazalo por New York\n",
    "    - MI: reemplazalo por Michigan\n",
    "    - GA: reemplazalo por Georgia\n",
    "    - ND: reemplazalo por North Dakota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buenos Aires', 'Ciudad Autónoma de Buenos Aires', 'Entre Ríos',\n",
       "       'Salta', 'Córdoba', 'Mendoza', 'Santa Fé', 'Unknown',\n",
       "       'Santiago Del Estero', 'Misiones', 'Catamarca', 'Formosa', 'Jujuy',\n",
       "       'La Rioja', 'La Pampa', 'San Juan', 'San Luis', 'Tucumán',\n",
       "       'Quebec', 'Ontario', 'Nova Scotia', 'British Columbia', 'Alberta',\n",
       "       'Manitoba', 'New Brunswick', 'Saskatchewan',\n",
       "       'Newfoundland and Labrador', 'Prince Edward Island', 'Yukon',\n",
       "       'Pennsylvania', 'NV', 'Iowa', 'VA', 'TX', 'Colorado', 'IN', 'CA',\n",
       "       'South Carolina', 'Washington', 'NY', 'Texas', 'ND', 'MI', 'Ohio',\n",
       "       'Florida', 'California', 'North Carolina', 'Michigan', 'GA',\n",
       "       'New York, NY'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['state_province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_estados = {'NV': 'Nevada',\n",
    "                'TX': 'Texas',\n",
    "                'IN': 'Indianapolis',\n",
    "                'CA': 'California',\n",
    "                'VA': 'Virginia',\n",
    "                'NY': 'New York',\n",
    "                'MI': 'Michigan',\n",
    "                'GA': 'Georgia',\n",
    "                'ND': 'North Dakota'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_valores(dataframe, columna, diccionario):\n",
    "    \n",
    "    '''Acepta un dataframe, una columna y un diccionario y reemplaza \n",
    "    los valores de la columna indicada segun el diccionario.\n",
    "    \n",
    "    Parametros:\n",
    "    - dataframe\n",
    "    - string: nombre de una columna del dataframe\n",
    "    - diccionario: los keys son los valores actuales y los values son los valores nuevos deseados\n",
    "    \n",
    "    Returns:\n",
    "    - none\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        for k, v in diccionario.items():\n",
    "            dataframe[columna].replace(to_replace=k, value=v, inplace=True)\n",
    "        \n",
    "        print(f'Se han reemplazado los valores segun el diccionario. Ahora los valores unicos de la columna {columna} son:')\n",
    "        print(dataframe['state_province'].unique())\n",
    "        \n",
    "    except:\n",
    "        print('No se ha podido realizar la operación.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han reemplazado los valores segun el diccionario. Ahora los valores unicos de la columna state_province son:\n",
      "['Buenos Aires' 'Ciudad Autónoma de Buenos Aires' 'Entre Ríos' 'Salta'\n",
      " 'Córdoba' 'Mendoza' 'Santa Fé' 'Unknown' 'Santiago Del Estero' 'Misiones'\n",
      " 'Catamarca' 'Formosa' 'Jujuy' 'La Rioja' 'La Pampa' 'San Juan' 'San Luis'\n",
      " 'Tucumán' 'Quebec' 'Ontario' 'Nova Scotia' 'British Columbia' 'Alberta'\n",
      " 'Manitoba' 'New Brunswick' 'Saskatchewan' 'Newfoundland and Labrador'\n",
      " 'Prince Edward Island' 'Yukon' 'Pennsylvania' 'Nevada' 'Iowa' 'Virginia'\n",
      " 'Texas' 'Colorado' 'Indianapolis' 'California' 'South Carolina'\n",
      " 'Washington' 'New York' 'North Dakota' 'Michigan' 'Ohio' 'Florida'\n",
      " 'North Carolina' 'Georgia' 'New York, NY']\n"
     ]
    }
   ],
   "source": [
    "reemplazar_valores(df, 'state_province', dicc_estados)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otros valores que tenemos más formateados son y que deberemos reemplazar:\n",
    "    - New York, NY. Deberéis reemplazarlo por \"New York\".\n",
    "    - 'Buenos Aires', 'Ciudad Autónoma de Buenos Aires'. En este caso deberéis poner en ambos casos \"Buenos Aires\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_ciudades = {'Ciudad Autónoma de Buenos Aires':'Buenos Aires',\n",
    "                 'New York, NY':'New York'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han reemplazado los valores segun el diccionario. Ahora los valores unicos de la columna state_province son:\n",
      "['Buenos Aires' 'Entre Ríos' 'Salta' 'Córdoba' 'Mendoza' 'Santa Fé'\n",
      " 'Unknown' 'Santiago Del Estero' 'Misiones' 'Catamarca' 'Formosa' 'Jujuy'\n",
      " 'La Rioja' 'La Pampa' 'San Juan' 'San Luis' 'Tucumán' 'Quebec' 'Ontario'\n",
      " 'Nova Scotia' 'British Columbia' 'Alberta' 'Manitoba' 'New Brunswick'\n",
      " 'Saskatchewan' 'Newfoundland and Labrador' 'Prince Edward Island' 'Yukon'\n",
      " 'Pennsylvania' 'Nevada' 'Iowa' 'Virginia' 'Texas' 'Colorado'\n",
      " 'Indianapolis' 'California' 'South Carolina' 'Washington' 'New York'\n",
      " 'North Dakota' 'Michigan' 'Ohio' 'Florida' 'North Carolina' 'Georgia']\n"
     ]
    }
   ],
   "source": [
    "reemplazar_valores(df, 'state_province', dicc_ciudades)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una vez realizados los pasos anteriores, crea una lista con los valores únicos de las provincias de las universidades.\n",
    "- Usando la API de geopy, extraed la latitud y la longitud de cada una de las provincias y almacenad los resultados en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_estado_prov = df['state_province'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_long(lista):\n",
    "    \n",
    "    '''\n",
    "    Acepta una lista de localidades y lo devuelve en un dataframe con los \n",
    "    latitudes y longitudes para cada localidad sacados con el API de geopy.\n",
    "    \n",
    "    Parametros:\n",
    "    - lista de localidades\n",
    "    \n",
    "    Returns:\n",
    "    - un dataframe con una columna de los localides, una columna de la latitud,\n",
    "    y una columna de la longitud    \n",
    "    '''\n",
    "    \n",
    "    diccionario ={'state_province':[], 'latitude': [], 'longitude': []}\n",
    "    \n",
    "    for i in lista:\n",
    "        if i == 'Unknown':\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                geolocator = Nominatim(user_agent='Cassia')\n",
    "                location = geolocator.geocode(i)\n",
    "                diccionario['state_province'].append(i)\n",
    "                diccionario['latitude'].append(location[1][0]) \n",
    "                diccionario['longitude'].append(location[1][1]) \n",
    "                \n",
    "            except:\n",
    "                print(f'No se puede conseguir la latitud y longitud de {i}')\n",
    "    \n",
    "    return pd.DataFrame(diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinados = lat_long(lista_estado_prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_province</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entre Ríos</td>\n",
       "      <td>-31.625284</td>\n",
       "      <td>-59.353958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_province   latitude  longitude\n",
       "0   Buenos Aires -34.607568 -58.437089\n",
       "1     Entre Ríos -31.625284 -59.353958"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinados.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buenos Aires', 'Entre Ríos', 'Salta', 'Córdoba', 'Mendoza',\n",
       "       'Santa Fé', 'Santiago Del Estero', 'Misiones', 'Catamarca',\n",
       "       'Formosa', 'Jujuy', 'La Rioja', 'La Pampa', 'San Juan', 'San Luis',\n",
       "       'Tucumán', 'Quebec', 'Ontario', 'Nova Scotia', 'British Columbia',\n",
       "       'Alberta', 'Manitoba', 'New Brunswick', 'Saskatchewan',\n",
       "       'Newfoundland and Labrador', 'Prince Edward Island', 'Yukon',\n",
       "       'Pennsylvania', 'Nevada', 'Iowa', 'Virginia', 'Texas', 'Colorado',\n",
       "       'Indianapolis', 'California', 'South Carolina', 'Washington',\n",
       "       'New York', 'North Dakota', 'Michigan', 'Ohio', 'Florida',\n",
       "       'North Carolina', 'Georgia'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinados['state_province'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una vez que tengáis los datos del ejercicio anterior en un dataframe, unidlo con el de las universidades que hemos sacado de la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_coordinados, on='state_province', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_province</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>web_pages</th>\n",
       "      <th>alpha_two_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Atlantida Argentina</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.atlantida.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Austral Buenos Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.austral.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_province                              name    country  \\\n",
       "0   Buenos Aires   Universidad Atlantida Argentina  Argentina   \n",
       "1   Buenos Aires  Universidad Austral Buenos Aires  Argentina   \n",
       "\n",
       "                      web_pages alpha_two_code   latitude  longitude  \n",
       "0  http://www.atlantida.edu.ar/             AR -34.607568 -58.437089  \n",
       "1    http://www.austral.edu.ar/             AR -34.607568 -58.437089  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comprobamos que haya salido\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Crea una BBDD en mysql que contenga las siguientes tablas:\n",
    "- Tabla países: donde encontraremos las siguientes columnas:\n",
    "    - idestado: primary key, integer, autoincremental\n",
    "    - nombre_pais: varchar\n",
    "    - nombre_provincia: varchar\n",
    "    - latitud: decimal\n",
    "    - longitud: decimal\n",
    "- Tabla universidades: donde encontraremos las siguientes columnas:\n",
    "    - iduniversidades: primary key, integer, autoincremental\n",
    "    - nombre_universidad: varchar\n",
    "    - agina_web: varchar\n",
    "    - paises_idestado: foreing key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_bbdd(nombre_bbdd, contraseña):\n",
    "    \n",
    "    '''\n",
    "    Acepta dos strings, un nombre para crear una base de datos en MySQL, y la contraseña\n",
    "    de MySQL para connectar con MySQL connector. Si la conexion falla o si la base de datos ya existe,\n",
    "    devuelve un mensaje de error.\n",
    "    \n",
    "    Parametros:\n",
    "    - string del nombre que poner a la base de datos\n",
    "    - string con la contraseña de MySQL\n",
    "    \n",
    "    Returns:\n",
    "    - none\n",
    "    '''\n",
    "    \n",
    "    conexion = mysql.connector.connect(host=\"localhost\",\n",
    "                                    user=\"root\",\n",
    "                                    password=contraseña)\n",
    "                                    \n",
    "    print(\"La conexión a MySQL se ha realizado con exito.\")\n",
    "    \n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {nombre_bbdd};\")\n",
    "        print(cursor)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La conexión a MySQL se ha realizado con exito.\n",
      "CMySQLCursor: CREATE DATABASE IF NOT EXISTS universida..\n"
     ]
    }
   ],
   "source": [
    "crear_bbdd('universidades', 'AlumnaAdalab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_insertar_tabla(nombre_bbdd, contraseña, query):\n",
    "    \n",
    "    '''\n",
    "    Acepta tres strings: el nombre de la base de datos, la contraseña de MySQL y una\n",
    "    query para crear una tabla en la base de datos indicado o para insertar datos en una\n",
    "    tabla de esa bbdd. Si la conexion falla o si la tabla ya existe, devuelve un mensaje de error.\n",
    "    \n",
    "    Parametros:\n",
    "    - string: nombre de la base de datos\n",
    "    - string: contraseña para MySQL\n",
    "    - string: query de creacion de tabla o insercion de datos\n",
    "    \n",
    "    Returns:\n",
    "    - none\n",
    "    '''\n",
    "    \n",
    "    conexion = mysql.connector.connect(user='root', password=contraseña,\n",
    "                                     host='127.0.0.1', database=nombre_bbdd)\n",
    "    cursor = conexion.cursor()\n",
    "    \n",
    "    try: \n",
    "        cursor.execute(query)\n",
    "        conexion.commit() \n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tabla_paises = \"\"\"CREATE TABLE IF NOT EXISTS `universidades`.`paises` (\n",
    "                        `idestado` INT NOT NULL AUTO_INCREMENT,\n",
    "                        `nombre_pais` VARCHAR(45) NOT NULL,\n",
    "                        `nombre_provincia` VARCHAR(45),\n",
    "                        `latitud` VARCHAR(45) NULL,\n",
    "                        `longitud` VARCHAR(45) NULL,\n",
    "                        PRIMARY KEY (`idestado`))\n",
    "                        ENGINE = InnoDB;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tabla_universidades = \"\"\"CREATE TABLE IF NOT EXISTS `universidades`.`universidades` (\n",
    "                            `iduniversidades` INT NOT NULL AUTO_INCREMENT,\n",
    "                            `nombre_universidad` VARCHAR(100) NOT NULL,\n",
    "                            `pagina_web` VARCHAR(100) NULL,\n",
    "                            `idestado` INT NOT NULL,\n",
    "                            PRIMARY KEY (`iduniversidades`),\n",
    "                            INDEX `fk_universidades_paises_idx` (`idestado` ASC) VISIBLE,\n",
    "                            CONSTRAINT `fk_universidades_paises`\n",
    "                                FOREIGN KEY (`idestado`)\n",
    "                                REFERENCES `universidades`.`paises` (`idestado`)\n",
    "                                ON DELETE CASCADE\n",
    "                                ON UPDATE CASCADE)\n",
    "                            ENGINE = InnoDB;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_insertar_tabla('universidades', 'AlumnaAdalab', query_tabla_paises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_insertar_tabla('universidades', 'AlumnaAdalab', query_tabla_universidades)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Introduce todo el código que habéis ido creando en funciones, siguiendo la misma lógica que hemos seguido en los pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya esta casi todo el codigo en funciones; solo falta el merge con el dataframe de latitud y longitud\n",
    "# yo lo metería junto con el codigo de geopy:\n",
    "\n",
    "def lat_long_merge(dataframe, user_agent):\n",
    "    \n",
    "    '''\n",
    "    Acepta un dataframe de datos de universidades del API de hipolabs y el\n",
    "    nombre de user agent para usar con el API de geopy. Devuelve el dataframe \n",
    "    con dos columnas nuevas indicando la latitud y la longitud del estado o \n",
    "    provincia de cada universidad sacados con el API de geopy.\n",
    "    \n",
    "    Parametros:\n",
    "    - dataframe de datos de universidades del API de hipolabs\n",
    "    - string: un nombre para usar como user agent con el API de geopy\n",
    "    \n",
    "    Returns:\n",
    "    - el dataframe origina con una columna para la latitud y una columna para la longitud    \n",
    "    '''\n",
    "    \n",
    "    lista_prov = dataframe['state_province'].unique().tolist()\n",
    "    \n",
    "    diccionario ={'state_province':[], 'latitude': [], 'longitude': []}\n",
    "    \n",
    "    for i in lista_prov:\n",
    "        if i == 'Unknown' or i is np.nan:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                geolocator = Nominatim(user_agent=user_agent)\n",
    "                location = geolocator.geocode(i)\n",
    "                diccionario['state_province'].append(i)\n",
    "                diccionario['latitude'].append(location[1][0]) \n",
    "                diccionario['longitude'].append(location[1][1]) \n",
    "                \n",
    "            except:\n",
    "                print(f'No se puede conseguir la latitud y longitud de {i}')\n",
    "    \n",
    "    df_lat_long = pd.DataFrame(diccionario)\n",
    "    \n",
    "    return dataframe.merge(df_lat_long, on='state_province', how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. BONUS\n",
    "- Introduce los datos en la BBDD de SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un nuevo dataframe sin duplicados de pais/provincia\n",
    "df_paises = df.drop_duplicates(subset=['state_province', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertamos los datos de la tabla de paises\n",
    "for indice, fila in df_paises.iterrows():\n",
    "\n",
    "    query_insert_paises = f\"\"\"INSERT INTO paises (nombre_pais, nombre_provincia, latitud, longitud)  \n",
    "        VALUES ('{fila[\"country\"]}', '{fila[\"state_province\"]}', '{fila[\"latitude\"]}', '{fila[\"longitude\"]}');\"\"\"\n",
    "    \n",
    "    crear_insertar_tabla(\"universidades\", \"AlumnaAdalab\", query_insert_paises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devolver_datos(nombre_bbdd, contraseña, query):\n",
    "    \n",
    "    ''' \n",
    "    Acepta el nombre de una base de datos, la contraseña de MySQL, y una query de SELECT de MySQL, y devuelve un\n",
    "    dataframe con los resultados del query. Si no funcion devuelve un mensaje de error.\n",
    "    \n",
    "    Parametros:\n",
    "    - string: nombre de una base de datos existente en MySQL\n",
    "    - string: contraseña de MySQL\n",
    "    - string: query tipo SELECT de MySQL\n",
    "    '''\n",
    "    \n",
    "    conexion = mysql.connector.connect(user='root', password=contraseña,\n",
    "                                     host='127.0.0.1', database=nombre_bbdd)\n",
    "    \n",
    "    try: \n",
    "        return pd.read_sql_query(query, conexion)\n",
    "    \n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        print(\"Error Code:\", err.errno)\n",
    "        print(\"SQLSTATE\", err.sqlstate)\n",
    "        print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7184/1694167056.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql_query(query, conexion)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idestado</th>\n",
       "      <th>state_province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Buenos Aires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Entre Ríos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idestado state_province\n",
       "0         1   Buenos Aires\n",
       "1         2     Entre Ríos"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saco los datos de la tabla creada en MySQL para obtener el idestado\n",
    "df_mysql_paises = devolver_datos('universidades', 'AlumnaAdalab', 'SELECT * FROM `paises`')\n",
    "df_mysql_paises.drop(columns=['nombre_pais','latitud', 'longitud'], inplace=True)\n",
    "df_mysql_paises.columns = ['idestado','state_province']\n",
    "df_mysql_paises.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# junto los datos de la tabla de paises de MySQL con una copia del dataframe\n",
    "df3 = df3.merge(df_mysql_paises, on='state_province', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_province</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>web_pages</th>\n",
       "      <th>alpha_two_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>idestado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Atlantida Argentina</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.atlantida.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad Austral Buenos Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.austral.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Universidad CAECE, Buenos Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.caece.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Instituto Universitario CEMA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.cema.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Instituto de Enseñanza Superior del Ejército</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>http://www.iese.edu.ar/</td>\n",
       "      <td>AR</td>\n",
       "      <td>-34.607568</td>\n",
       "      <td>-58.437089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Virginia University of Lynchburg</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.vul.edu/</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Voorhees University</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.voorhees.edu/</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>West Virginia State University</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.wvstateu.edu/</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Wiley College</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.wileyc.edu/</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Winston-Salem State University</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.wssu.edu/</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2507 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_province                                          name  \\\n",
       "0      Buenos Aires               Universidad Atlantida Argentina   \n",
       "1      Buenos Aires              Universidad Austral Buenos Aires   \n",
       "2      Buenos Aires               Universidad CAECE, Buenos Aires   \n",
       "3      Buenos Aires                  Instituto Universitario CEMA   \n",
       "4      Buenos Aires  Instituto de Enseñanza Superior del Ejército   \n",
       "...             ...                                           ...   \n",
       "2502        Unknown              Virginia University of Lynchburg   \n",
       "2503        Unknown                           Voorhees University   \n",
       "2504        Unknown                West Virginia State University   \n",
       "2505        Unknown                                 Wiley College   \n",
       "2506        Unknown                Winston-Salem State University   \n",
       "\n",
       "            country                     web_pages alpha_two_code   latitude  \\\n",
       "0         Argentina  http://www.atlantida.edu.ar/             AR -34.607568   \n",
       "1         Argentina    http://www.austral.edu.ar/             AR -34.607568   \n",
       "2         Argentina      http://www.caece.edu.ar/             AR -34.607568   \n",
       "3         Argentina       http://www.cema.edu.ar/             AR -34.607568   \n",
       "4         Argentina       http://www.iese.edu.ar/             AR -34.607568   \n",
       "...             ...                           ...            ...        ...   \n",
       "2502  United States          https://www.vul.edu/             US        NaN   \n",
       "2503  United States     https://www.voorhees.edu/             US        NaN   \n",
       "2504  United States     https://www.wvstateu.edu/             US        NaN   \n",
       "2505  United States       https://www.wileyc.edu/             US        NaN   \n",
       "2506  United States         https://www.wssu.edu/             US        NaN   \n",
       "\n",
       "      longitude  idestado  \n",
       "0    -58.437089         1  \n",
       "1    -58.437089         1  \n",
       "2    -58.437089         1  \n",
       "3    -58.437089         1  \n",
       "4    -58.437089         1  \n",
       "...         ...       ...  \n",
       "2502        NaN         7  \n",
       "2503        NaN         7  \n",
       "2504        NaN         7  \n",
       "2505        NaN         7  \n",
       "2506        NaN         7  \n",
       "\n",
       "[2507 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elimino las filas duplicadas creadas en el merge y reseteo los indices para que esten en orden\n",
    "df3.drop_duplicates(subset=['name', 'state_province'], inplace=True)\n",
    "df3.reset_index(drop=True, inplace=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quito comillas de los valores del dataframe por si da errores de syntaxes de MySQL\n",
    "df.replace(r'\"*', '', regex=True, inplace=True)\n",
    "df.replace(r\"'*\", \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'John F. Kennedy\"\", \"http://www.kennedy.edu.ar/\", \"1\")' at line 2\n",
      "Error Code: 1064\n",
      "SQLSTATE 42000\n",
      "Message You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'John F. Kennedy\"\", \"http://www.kennedy.edu.ar/\", \"1\")' at line 2\n",
      "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Juan Agustín Maza\"\", \"http://www.umaza.edu.ar/\", \"7\")' at line 2\n",
      "Error Code: 1064\n",
      "SQLSTATE 42000\n",
      "Message You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Juan Agustín Maza\"\", \"http://www.umaza.edu.ar/\", \"7\")' at line 2\n",
      "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'General Manuel Belgrano\"\", \"http://www.unlu.edu.ar/Belgrano.htm\", \"7\")' at line 2\n",
      "Error Code: 1064\n",
      "SQLSTATE 42000\n",
      "Message You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'General Manuel Belgrano\"\", \"http://www.unlu.edu.ar/Belgrano.htm\", \"7\")' at line 2\n",
      "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'San Juan Bosco\"\", \"http://www.unp.edu.ar/\", \"7\")' at line 2\n",
      "Error Code: 1064\n",
      "SQLSTATE 42000\n",
      "Message You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'San Juan Bosco\"\", \"http://www.unp.edu.ar/\", \"7\")' at line 2\n",
      "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Santo Tomás de Aquino\"\", \"http://www.unsta.edu.ar/\", \"7\")' at line 2\n",
      "Error Code: 1064\n",
      "SQLSTATE 42000\n",
      "Message You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'Santo Tomás de Aquino\"\", \"http://www.unsta.edu.ar/\", \"7\")' at line 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7184/2760988040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         VALUES (\"{fila['name']}\", \"{fila['web_pages']}\", \"{fila['idestado']}\");'''\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcrear_insertar_tabla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"universidades\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AlumnaAdalab\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_insert_unis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7184/2075669383.py\u001b[0m in \u001b[0;36mcrear_insertar_tabla\u001b[0;34m(nombre_bbdd, contraseña, query)\u001b[0m\n\u001b[1;32m     15\u001b[0m     '''\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     conexion = mysql.connector.connect(user='root', password=contraseña,\n\u001b[0m\u001b[1;32m     18\u001b[0m                                      host='127.0.0.1', database=nombre_bbdd)\n\u001b[1;32m     19\u001b[0m     \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconexion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mysql/connector/pooling.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mCMySQLConnection\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_pure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCMySQLConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMySQLConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_default_conn_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mysql/connector/abstracts.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;31m# Server does not allow to run any other statement different from ALTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;31m# when user's password has been expired.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36m_open_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcnx_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_str_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_converter_str_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inserto los datos de la tabla de universidades\n",
    "# no funciona pero dejo el código para mostrar que lo he intentado\n",
    "\n",
    "for indice, fila in df3.iterrows():\n",
    "\n",
    "    query_insert_unis = f'''INSERT INTO universidades (nombre_universidad, pagina_web, idestado)  \n",
    "        VALUES (\"{fila['name']}\", \"{fila['web_pages']}\", \"{fila['idestado']}\");'''\n",
    "    \n",
    "    crear_insertar_tabla(\"universidades\", \"AlumnaAdalab\", query_insert_unis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
